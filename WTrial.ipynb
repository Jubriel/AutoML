{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Ademonla:\n",
    "#     def __init__(self, scoring_function = 'f1', n_iter = 50):\n",
    "#         self.scoring_function = scoring_function\n",
    "#         self.n_iter = n_iter\n",
    "    \n",
    "#     def fit(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Full_course(file, target):\n",
    "    # importing all required libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier, SGDRegressor, Lasso, ElasticNet\n",
    "    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "    from sklearn.ensemble import RandomForestClassifier,   RandomForestRegressor,\\\n",
    "         VotingClassifier, VotingRegressor, ExtraTreesClassifier,ExtraTreesRegressor, GradientBoostingClassifier,GradientBoostingRegressor\n",
    "    from sklearn.svm import SVC, SVR\n",
    "    from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "    from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "    from xgboost.sklearn import XGBClassifier, XGBRegressor\n",
    "    from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "    from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "    \n",
    "    \n",
    "    # from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate, StratifiedKFold\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.preprocessing import StandardScaler , RobustScaler\n",
    "    import category_encoders as ce\n",
    "    from sklearn.impute import KNNImputer, SimpleImputer\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # Loading the dataframe\n",
    "    TFrame = pd.read_csv(file,encoding='cp1252')\n",
    "\n",
    "    print(TFrame.shape)\n",
    "\n",
    "    # Removes columns with more than 70% missing values\n",
    "    crazy = [i for i in TFrame.columns if TFrame[i].isna().sum() >= 0.7*len(TFrame[i])]\n",
    "    TFrame = TFrame.drop(crazy, axis=1)\n",
    "\n",
    "   # Sorting based on datatypes\n",
    "    date = [d for d in TFrame.columns if 'Date' in d]\n",
    "    cat = [n for n in TFrame.columns if TFrame[n].dtype == object and n not in date]\n",
    "    num = [p for p in TFrame.columns if p not in cat]\n",
    "\n",
    "    # filling up missing values\n",
    "    imp = KNNImputer(n_neighbors=5)\n",
    "    missing_num = [i for i in num if TFrame[i].isna().sum() != 0]\n",
    "    if missing_num != []:\n",
    "        TFrame[missing_num] = imp.fit_transform(TFrame[missing_num])\n",
    "\n",
    "    obj = SimpleImputer(missing_values = np.nan, strategy='most_frequent')\n",
    "    missing_cat = [i for i in cat if TFrame[i].isna().sum() != 0]\n",
    "    if missing_cat != []:\n",
    "        TFrame[missing_cat] = obj.fit_transform(TFrame[missing_cat])\n",
    "        TFrame[cat] = TFrame[cat].astype('category')\n",
    "\n",
    "    # Dealing with date features\n",
    "    if date != []:\n",
    "        TFrame[date] = obj.fit_transform(TFrame[date])\n",
    "\n",
    "        for i in date:\n",
    "            TFrame[i] = pd.to_datetime(TFrame[i]).astype('category')\n",
    "            TFrame[f'{i}_months'] = TFrame[i].dt.month.astype('category')\n",
    "            TFrame[f'{i}_days'] = TFrame[i].dt.day.astype('category')\n",
    "            TFrame[f'{i}_years'] = TFrame[i].dt.year.astype('category')\n",
    "\n",
    "        TFrame = TFrame.drop(date, axis = 1)\n",
    "    \n",
    "    # # Skewness in data\n",
    "    # sk = [i for i in TFrame.columns if abs(TFrame[i].skew()) > 1]\n",
    "    # for i in sk:\n",
    "    #     TFrame[i] = TFrame[i].apply(lambda i: np.log(i) if i > 0 else 0)\n",
    "\n",
    "    # Removing columns with high variance\n",
    "    uniq = [i for i in cat if TFrame[i].nunique() >= 0.7 * TFrame.shape[0]]\n",
    "    TFrame = TFrame.drop(uniq, axis=1)\n",
    "\n",
    "    X = TFrame.drop(target, axis =1)\n",
    "    y = TFrame[target]\n",
    "\n",
    "    # Train and test split - test size at 20%\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size = 0.2, random_state = 101)\n",
    "    t = [i for i in cat if i not in uniq]\n",
    "\n",
    "    #Selecting Classification or Regression--- Ensemble\n",
    "    if y.nunique() < 10: \n",
    "        # category encoding \n",
    "        encode = ce.BinaryEncoder(t)\n",
    "        trainX = encode.fit_transform(trainX)\n",
    "        testX = encode.transform(testX)\n",
    "\n",
    "        # Resampling\n",
    "        if np.mean(list(trainX.value_counts())) > 1.5 * min(list(trainX.value_counts())):\n",
    "            oversample = SMOTE()\n",
    "            trainX, trainy = oversample.fit_resample(trainX, trainy)\n",
    "\n",
    "        \n",
    "        # Feature Selection \n",
    "        if len(trainX.columns) > 20:\n",
    "            dec = PCA(0.98)\n",
    "            trainX = dec.fit_transform(trainX)\n",
    "            testX = dec.transform(testX)\n",
    "\n",
    "        # Standardization\n",
    "        sc = RobustScaler()\n",
    "        trainX = sc.fit_transform(trainX)\n",
    "        testX = sc.transform(testX)\n",
    "\n",
    "        # Modeling\n",
    "        # Finding the BaseLine perfomance of the various models\n",
    "        models = []\n",
    "\n",
    "        # Adding algorthms\n",
    "        models.append(('cat', CatBoostClassifier(verbose=0)))\n",
    "        models.append(('mlp', MLPClassifier(verbose=0)))\n",
    "        models.append(('lgr', LogisticRegression(verbose=0)))\n",
    "        models.append(('svc', SVC(probability=True)))\n",
    "        models.append(('knc', KNeighborsClassifier()))\n",
    "        models.append(('lgbm', LGBMClassifier()))\n",
    "        models.append(('dctc', DecisionTreeClassifier()))\n",
    "        models.append(('sgd', SGDClassifier()))\n",
    "        models.append(('ext', ExtraTreesClassifier()))\n",
    "        models.append(('rfc', RandomForestClassifier()))\n",
    "        models.append(('gbc', GradientBoostingClassifier()))\n",
    "        models.append(('xgb', XGBClassifier()))\n",
    "\n",
    "        # evaluate -cross validation- each model in turn\n",
    "        results = []\n",
    "        mods = []\n",
    "        names = []\n",
    "        scoring =['roc_auc', 'f1']\n",
    "        for name, model in models:\n",
    "            kfold = StratifiedKFold(n_splits=7, shuffle= True)\n",
    "            cv_results = cross_validate(model, trainX, trainy, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "            results.append([cv_results['test_roc_auc'].mean(), cv_results[f'test_f1'].mean()])\n",
    "            mods.append(model)\n",
    "            names.append(name)\n",
    "        alg = pd.DataFrame({'models': models, 'roc_auc':[m[0] for m in results] , 'f1': [m[1] for m in results]})\n",
    "        # Ensemble\n",
    "        vtc = VotingClassifier([n for n in alg.sort_values('roc_auc', ascending=False)['models'][:2]], \n",
    "                                weights =[i for i in alg['roc_auc'].nlargest(2)], voting='soft')\n",
    "        vtc.fit(trainX, trainy) # fit the model in the Train set\n",
    "        # if vote < alg.metric.max():\n",
    "        #   alg.metric.max()['models']\n",
    "        \n",
    "        \n",
    "        # Predict the Test file\n",
    "        ypred = vtc.predict(testX)\n",
    "        ypredp = vtc.predict_proba(testX)\n",
    "       \n",
    "        # Check the Scores\n",
    "        sol = vtc.score(trainX, trainy)    \n",
    "        sol1 = vtc.score(testX, testy)\n",
    "\n",
    "    else:\n",
    "        # category encoding \n",
    "        encode = ce.TargetEncoder(cols=t, smoothing=8, min_samples_leaf=5)\n",
    "        trainX = encode.fit_transform(trainX, trainy)\n",
    "        testX = encode.transform(testX)\n",
    "        \n",
    "\n",
    "        # Feature Selection \n",
    "        if len(trainX.columns) > 20:\n",
    "            dec = PCA(0.98)\n",
    "            trainX = dec.fit_transform(trainX)\n",
    "            testX = dec.transform(testX)\n",
    "       \n",
    "\n",
    "        # Standardization\n",
    "        sc = RobustScaler()\n",
    "        trainX = sc.fit_transform(trainX)\n",
    "        testX = sc.transform(testX)\n",
    "        \n",
    "\n",
    "        # Modeling\n",
    "        # Finding the BaseLine perfomance of the various models\n",
    "\n",
    "        # Prepare models\n",
    "        models = []\n",
    "\n",
    "        # Adding algorthms\n",
    "        models.append(('cat', CatBoostRegressor(verbose=0)))\n",
    "        models.append(('mlp', MLPRegressor(verbose=0)))\n",
    "        models.append(('lr', LinearRegression()))\n",
    "        models.append(('lss', Lasso()))\n",
    "        models.append(('eln', ElasticNet()))\n",
    "        models.append(('svc', SVR()))\n",
    "        models.append(('knc', KNeighborsRegressor()))\n",
    "        models.append(('dctr', DecisionTreeRegressor())) \n",
    "        models.append(('sgd', SGDRegressor()))\n",
    "        models.append(('lgbm', LGBMRegressor()))\n",
    "        models.append(('ext', ExtraTreesRegressor()))\n",
    "        models.append(('rfr', RandomForestRegressor()))\n",
    "        models.append(('gbr', GradientBoostingRegressor()))\n",
    "        models.append(('xgb', XGBRegressor()))\n",
    "       \n",
    "        # evaluate -cross validation- each model in turn\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring =['neg_root_mean_squared_error', 'r2']\n",
    "        for name, model in models:\n",
    "            kfold = KFold(n_splits=7, shuffle= True)\n",
    "            cv_results = cross_validate(model, trainX, trainy, cv=kfold, scoring=scoring, return_train_score=True)\n",
    "            results.append([-cv_results['test_neg_root_mean_squared_error'].mean(),cv_results[f'test_r2'].mean()])\n",
    "            names.append(name)\n",
    "        alg = pd.DataFrame({'models': models, 'RMSE':[m[0] for m in results], 'R2':[m[1] for m in results]})\n",
    "        \n",
    "        # Ensemble\n",
    "        vtr = VotingRegressor([n for n in alg.sort_values('RMSE', ascending=True)['models']][:2], \n",
    "                                weights =[i for i in alg['RMSE'].nsmallest(2)], voting = 'hard')\n",
    "        vtr.fit(trainX, trainy) # fit the model in the Train set\n",
    "\n",
    "        \n",
    "        # Predict the Test file\n",
    "        ypred = vtr.predict(testX)\n",
    "    \n",
    "        # Check the Scores\n",
    "        sol = vtr.score(trainX, trainy)    \n",
    "        sol1 = vtr.score(testX, testy)\n",
    "\n",
    "    # Outcomes\n",
    "    algp = pd.DataFrame({f'{target}': testy ,'Predicted': ypred})\n",
    "    Scores = f'Ensemble: The Train score is {sol}, The Test score is {sol1}'\n",
    "    print(Scores)\n",
    "\n",
    "\n",
    "    return alg, algp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jubriel/anaconda3/envs/ML/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "Full_course('creditcard.csv', 'Class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "a091963de693db952aae2745377e7fb82d3cad659371ccc8c5d4df4ae20bc0c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
